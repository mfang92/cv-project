{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "raN8W9BU7TBF"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import cv2\n",
        "import scipy.ndimage as ndimage"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ms3uvGKARU_p",
        "outputId": "f581b1f5-2eba-4698-98f6-452b29a25dd8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed 101 frames\n"
          ]
        }
      ],
      "source": [
        "capture = cv2.VideoCapture('video.mov')\n",
        "\n",
        "n = 0\n",
        "frames = []\n",
        "while True:\n",
        "    successful, next_frame = capture.read()\n",
        "    if not successful:\n",
        "        # No more frames to read\n",
        "        print(\"Processed %d frames\" % n)\n",
        "        break\n",
        "    frames.append(next_frame)\n",
        "    n += 1\n",
        "# Now we have an image! We can process that as we would.\n",
        "\n",
        "# We have to give up the file at the end.\n",
        "capture.release()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D2SsAvriXoyS",
        "outputId": "a7dd99ad-08d4-4a79-e868-11282e8cdee7"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(1920, 1440, 3)"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "height, width, channels = frames[0].shape\n",
        "height, width, channels\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "cHzO9g-88GAH"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "OpenCV: FFMPEG: tag 0x5634504d/'MP4V' is not supported with codec id 12 and format 'mp4 / MP4 (MPEG-4 Part 14)'\n",
            "OpenCV: FFMPEG: fallback to use tag 0x7634706d/'mp4v'\n"
          ]
        }
      ],
      "source": [
        "def downsize_frame(frame, factor = 2, sigma = 9):\n",
        "  frame_blurred = cv2.GaussianBlur(frame, (sigma, sigma), 0)\n",
        "  return frame_blurred[::factor, ::factor]\n",
        "\n",
        "factor = 4\n",
        "downsized_size = (width // factor, height // factor) # w,h\n",
        "output_path = 'output_downsized.mp4'\n",
        "output_format = cv2.VideoWriter_fourcc('M','P','4','V')\n",
        "output_fps = 30\n",
        "downsized_output = cv2.VideoWriter(output_path, output_format, output_fps, downsized_size)\n",
        "\n",
        "for frame in frames:\n",
        "  output_frame = downsize_frame(frame, factor=factor)\n",
        "  downsized_output.write(output_frame)\n",
        "\n",
        "downsized_output.release()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/Users/masonfang/Documents/6.8301/project\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "print(os.getcwd())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 106,
      "metadata": {
        "id": "E7-6UOK6DCPm"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Using cpu device\n",
            "hi\n"
          ]
        }
      ],
      "source": [
        "# first model\n",
        "# a bunch of 3x3 convolutions\n",
        "# https://pytorch.org/tutorials/beginner/blitz/cifar10_tutorial.html\n",
        "\n",
        "device = (\n",
        "    \"cuda\"\n",
        "    if torch.cuda.is_available()\n",
        "    else \"cpu\"\n",
        ")\n",
        "print(f\"Using {device} device\")\n",
        "\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "# test = cv2.resize(frames[0], (10, 10))\n",
        "# test_r = torch.tensor(test[:, :, 0]) # red component\n",
        "bw_frames = np.array([np.sum(frame, axis=-1)/3 for frame in frames]).astype('float32')\n",
        "\n",
        "test = torch.tensor(bw_frames[0])\n",
        "test = test[None,:,:]\n",
        "\n",
        "print(\"hi\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 107,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([[55.6667, 56.6667, 58.0000,  ..., 29.3333, 29.3333, 29.3333]])\n"
          ]
        }
      ],
      "source": [
        "print(test[:,:,0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 113,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "torch.Size([1, 1920, 1440])\n"
          ]
        }
      ],
      "source": [
        "class Net(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.conv1 = nn.Conv2d(1, 3, 3, bias=False)\n",
        "        \n",
        "        # self.conv2 = nn.Conv2d(3, 3, 3)\n",
        "        # add more later?\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = F.relu(self.conv1(x))\n",
        "        # out = F.relu(self.conv2(out))\n",
        "        return out\n",
        "net = Net()\n",
        "torch.manual_seed(0)\n",
        "print(test.size())\n",
        "\n",
        "# a = test.reshape(test, (1, ...))\n",
        "# print(test_res)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 109,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "torch.Size([1, 1920, 1440])\n",
            "tensor([[ 55.6667,  56.6667,  58.3333,  ...,  36.3333,  35.3333,  35.3333],\n",
            "        [ 56.6667,  57.6667,  58.3333,  ...,  35.3333,  35.3333,  35.3333],\n",
            "        [ 58.0000,  58.0000,  58.3333,  ...,  35.3333,  34.3333,  34.3333],\n",
            "        ...,\n",
            "        [ 29.3333,  29.3333,  29.3333,  ..., 126.6667, 139.6667, 145.6667],\n",
            "        [ 29.3333,  29.3333,  29.3333,  ..., 106.6667, 126.6667, 143.6667],\n",
            "        [ 29.3333,  28.3333,  28.3333,  ...,  89.6667, 108.6667, 133.6667]])\n",
            "tensor([[[0., 0., 0.,  ..., 0., 0., 0.],\n",
            "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "         ...,\n",
            "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "         [0., 0., 0.,  ..., 0., 0., 0.]]], grad_fn=<ReluBackward0>)\n"
          ]
        }
      ],
      "source": [
        "print(test.size())\n",
        "print(test[0])\n",
        "print(net(test))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[[167 170 175 ... 109 106 106]\n",
            " [170 173 175 ... 106 106 106]\n",
            " [174 174 175 ... 106 103 103]\n",
            " ...\n",
            " [ 88  88  88 ... 380 419 437]\n",
            " [ 88  88  88 ... 320 380 431]\n",
            " [ 88  85  85 ... 269 326 401]]\n",
            "(1920, 1440, 3)\n",
            "101\n"
          ]
        }
      ],
      "source": [
        "print(bw_frames[0])\n",
        "print(frames[0].shape)\n",
        "print(len(frames))\n",
        "\n",
        "# print(frames[0])\n",
        "# in_video = torch.tensor(frames)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
